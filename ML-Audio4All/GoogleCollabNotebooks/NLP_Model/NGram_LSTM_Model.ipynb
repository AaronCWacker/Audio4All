{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NGram_LSTM_Model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"12HdqXPuP_ARdBggo9q7-hJquTw49AkRk","authorship_tag":"ABX9TyOt2Vc7haxt6oLG3+jtl+n+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EjK7MfyAg_1-"},"source":["# Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uNBTpOQWg30n","executionInfo":{"status":"ok","timestamp":1618518215747,"user_tz":420,"elapsed":9324,"user":{"displayName":"James Elliott","photoUrl":"","userId":"01294451348328680747"}},"outputId":"8804a4ed-99aa-475d-9778-73d7c3989b98"},"source":["import numpy as np\n","np.set_printoptions(threshold=np.inf)\n","import tensorflow as tf\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import collections\n","from sklearn.preprocessing import MinMaxScaler\n","from random import randint\n","\n","import pickle\n","\n","print(torch.__version__)\n","import time\n","\n","import os\n","import shutil\n","import copy\n","\n","!pip install mido\n","import mido"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.8.1+cu101\n","Collecting mido\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/0a/81beb587b1ae832ea6a1901dc7c6faa380e8dd154e0a862f0a9f3d2afab9/mido-1.2.9-py2.py3-none-any.whl (52kB)\n","\u001b[K     |████████████████████████████████| 61kB 3.5MB/s \n","\u001b[?25hInstalling collected packages: mido\n","Successfully installed mido-1.2.9\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s48zfaVuz8U5"},"source":["# Load Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LBA37DBzhLNu","executionInfo":{"status":"ok","timestamp":1618518275600,"user_tz":420,"elapsed":8454,"user":{"displayName":"James Elliott","photoUrl":"","userId":"01294451348328680747"}},"outputId":"9d99254d-fea0-48e3-9a30-47336332e9ff"},"source":["tensorLocation = \"/content/drive/Shareddrives/Senior Design - Audio Project/MIDI Datasets/Datasets/AllDataSetsCombined/Essential_Midi_ProgressionsOnly/tensor_essentialDataset.pt\"\n","dataset = torch.load(tensorLocation)\n","\n","print(dataset.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1416, 4, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Hb5tZqIf2IXw"},"source":["# Load Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FDIPgiMR2IX2","executionInfo":{"status":"ok","timestamp":1618518275600,"user_tz":420,"elapsed":8454,"user":{"displayName":"James Elliott","photoUrl":"","userId":"01294451348328680747"}},"outputId":"9d99254d-fea0-48e3-9a30-47336332e9ff"},"source":["tensorLocation = \"/content/drive/Shareddrives/Senior Design - Audio Project/MIDI Datasets/Datasets/AllDataSetsCombined/Essential_Midi_ProgressionsOnly/tensor_essentialDataset.pt\"\n","dataset = torch.load(tensorLocation)\n","\n","print(dataset.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1416, 4, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jDqPmDLXOKCJ"},"source":["# Mido Helper Functions"]},{"cell_type":"code","metadata":{"id":"rT4n5QpIONP2"},"source":["from mido import Message, MidiFile, MidiTrack\n","import copy\n","\n","def listToMidi(chord_list,\n","               dir_path = './',\n","               file_name = \"new_song.mid\",\n","               program = 12,\n","               dt = 256,\n","               veloON = 64,\n","               veloOFF = 127,\n","               printOut = True,\n","               saveMidiFile=True,\n","               completePath = False):\n","  \"\"\"\n","  converts midi value chords into a midi file with given specifications.\n","  \"\"\"\n","  mid = MidiFile()\n","  track = MidiTrack()\n","  mid.tracks.append(track)\n","\n","  #initialize instrument type\n","  track.append(Message('program_change', program=12, time=0))\n","  #Loop through each all chords in list\n","  for chord in chord_list:\n","    start = True\n","    \n","    #turn chord(s) on\n","    for note in chord:\n","      if start == True:\n","        \n","        track.append(Message('note_on', note=note, velocity=veloON, time=dt))\n","        start = False\n","      else:\n","        track.append(Message('note_on', note=note, velocity=veloON, time=0))\n","\n","    start = True\n","    #turn chord(s) off\n","    for note in chord:\n","      if start == True:\n","        track.append(Message('note_off', note=note, velocity=veloOFF, time=dt))\n","        start = False\n","      else:\n","        track.append(Message('note_off', note=note, velocity=veloOFF, time=0))\n","\n","  #print created track\n","  if printOut == True:\n","    for msg in mid:\n","      print(msg)\n","  \n","  #save midi file\n","  if saveMidiFile == True and completePath == False:\n","    complete_path = os.path.join(dir_path,file_name)\n","    #print(complete_path)\n","    mid.save(complete_path)\n","    print(\"\\nfile saved @\\n{}\".format(complete_path))\n","  elif completePath != False:\n","    mid.save(completePath)\n","##########################################################\n","##########################################################\n","#NOT WORKING RIGHT NOW\n","def midiExtend(file_path,dupNum=2,save_path = False):\n","  mid = MidiFile(file_path)\n","\n","  final_tracks = MidiTrack()\n","  for i in range(dupNum):\n","    for track in mid:\n","      #print(track)\n","      final_tracks.append(track)\n","\n","  #create new file name\n","  file_name = \"midi_extended\"\n","  num = str(dupNum)\n","  extension = \".mid\"\n","  full_name = file_name + num + extension\n","\n","  path = \"/\".join(file_path.split(\"/\")[0:-1])\n","  #print(\"Path {}\\n\".format(path))\n","  #print(full_name)\n","  mid_final = MidiFile()\n","  mid_final.tracks.append(final_tracks)\n","  \n","  final_path = os.path.join(path,full_name)\n","  mid_final.save(final_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s1egy2RQHD9V"},"source":["## Embedding"]},{"cell_type":"code","metadata":{"id":"5k8Dlp8Zv1Qm"},"source":["def datasetEmbedder(dataset,inputLength=3):\n","  \"\"\"\n","  dataset: tensorflow dataset with dimensions (total_progs,progression length,notes in chord)\n","  inputLength: # of chords played.\n","\n","  Function seperates progressions into \"input\" & \"target\"\n","  \"\"\"\n","  assert len(dataset[0]) > inputLength, \"inputLength needs to be less than progression length\"\n","  #quadgrams = [(progression[:3],progression[3]) for progression in dataset]\n","  if inputLength != len(dataset[0]):\n","    grams = [(progression[:inputLength],progression[inputLength]) for progression in dataset]\n","  \n","  return grams\n","\n","def decoder(code=0):\n","  \"\"\"\n","  code: input encrypted recommendation from model\n","  \"\"\"\n","  string = ix_to_chord[code]\n","  string = string.replace(\"[\",\" \")\n","  string = string.replace(\"]\",\" \")\n","  string = list(string.split(\" \"))\n","  final_chord = [int(x) for x in string if x != \"\"]\n","  return final_chord\n","\n","#######################Lookup Table Functions###################################\n","def createLookup(dataset):\n","  #create chords as a singular word\n","  vocab = []\n","  for prog in dataset:\n","    for chord in prog:\n","      tmp_chord = str(chord.numpy()) #convert chord to string\n","      vocab.append(tmp_chord)\n","  vocab = set(vocab)\n","  print(\"# of Chords in Vocab: {}\".format(len(vocab)))\n","\n","  #create lookup table\n","  word_to_ix = {word:i for i,word in enumerate(vocab)} #encode\n","  ix_to_chord = {i:word for i,word in enumerate(vocab)} #decode\n","\n","  return vocab, word_to_ix, ix_to_chord\n","\n","def saveLookUp(encode_dict,decode_dict,dirPath):\n","  \"\"\"\n","  encode: word_to_ix\n","  decode: ix_to_chord\n","  \"\"\"\n","  file_encode = r\"lookUp_encode.txt\"\n","  file_decode = r\"lookUp_decode.txt\"\n","  #save files\n","  with open(os.path.join(dirPath,file_encode), \"wb\") as myFile_encode:\n","    pickle.dump(encode_dict, myFile_encode)\n","\n","  with open(os.path.join(dirPath,file_decode), \"wb\") as myFile_decode:\n","    pickle.dump(decode_dict, myFile_decode)\n","\n","  print(\"Files Saved @:\\n{}\".format(dirPath))\n","\n","def loadLookUp(dirPath):\n","  \"\"\"\n","  reverse of saveLookUp()\n","  \"\"\"\n","  file_encode = r\"lookUp_encode.txt\"\n","  file_decode = r\"lookUp_decode.txt\"\n","\n","  with open(os.path.join(dirPath,file_encode), \"rb\") as myFile_encode:\n","    encode_dict = pickle.load(myFile_encode)\n","\n","  with open(os.path.join(dirPath,file_decode), \"rb\") as myFile_decode:\n","    decode_dict = pickle.load(myFile_decode)\n","\n","  assert len(encode_dict) == len(decode_dict), \"encode and decode must be same length\"\n","\n","  vocab = encode_dict #used for the len(vocab) for embed dimensions\n","\n","  return encode_dict, decode_dict, vocab\n","########################################################################\n","########################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h1sXzPQ6MdGF","executionInfo":{"status":"ok","timestamp":1618526093050,"user_tz":420,"elapsed":636,"user":{"displayName":"James Elliott","photoUrl":"","userId":"01294451348328680747"}},"outputId":"2c0056de-76e2-469d-d517-6c29c8a18ddf"},"source":["#####################EMBEDDING CREATION####################\n","CONTEXT_SIZE = 3 #decides how long the input is for next recommendation\n","EMBEDDING_DIM = 100 #how many dimensions we want inside the linear model to have\n","\n","###seperates progressions into input and target as a tuple###\n","quadgrams = datasetEmbedder(dataset,inputLength=CONTEXT_SIZE)\n","\n","###create new LookUp Table from Dataset###\n","#vocab, word_to_ix, ix_to_chord = createLookup(dataset) #create new lookup table\n","\n","#save Lookup Table(s)\n","saveDir = r\"/content/drive/Shareddrives/Senior Design - Audio Project/MIDI Datasets/Models/NLP Models/lookup_tables\"\n","#saveLookUp(word_to_ix,ix_to_chord,saveDir)\n","\n","###load Lookup Table(s)###\n","word_to_ix, ix_to_chord,vocab = loadLookUp(saveDir)\n","\n","\n","print(\"Encoder\\n{}\".format(word_to_ix))\n","print(\"Decoder\\n{}\".format(ix_to_chord))\n","print(\"Number of Chord Options: {}\".format(len(word_to_ix)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Encoder\n","{'[53 56 60]': 0, '[46 49 53]': 1, '[45 48 52]': 2, '[47 50 53]': 3, '[54 57 61]': 4, '[58 62 65]': 5, '[61 64 67]': 6, '[70 73 76]': 7, '[68 71 74]': 8, '[65 68 71]': 9, '[57 61 64]': 10, '[59 63 66]': 11, '[61 65 68]': 12, '[50 54 57]': 13, '[45 49 52]': 14, '[53 57 60]': 15, '[47 50 54]': 16, '[55 58 62]': 17, '[61 64 68]': 18, '[51 54 57]': 19, '[60 63 67]': 20, '[59 62 66]': 21, '[48 52 55]': 22, '[64 67 70]': 23, '[66 70 73]': 24, '[54 58 61]': 25, '[49 52 55]': 26, '[67 70 74]': 27, '[43 46 50]': 28, '[57 60 64]': 29, '[54 57 60]': 30, '[65 68 72]': 31, '[48 51 55]': 32, '[62 66 69]': 33, '[63 67 70]': 34, '[66 69 73]': 35, '[60 63 66]': 36, '[50 53 56]': 37, '[41 44 48]': 38, '[64 67 71]': 39, '[64 68 71]': 40, '[68 72 75]': 41, '[62 65 69]': 42, '[58 61 65]': 43, '[44 47 51]': 44, '[52 55 59]': 45, '[48 51 54]': 46, '[42 45 49]': 47, '[67 70 73]': 48, '[66 69 72]': 49, '[53 56 59]': 50, '[49 53 56]': 51, '[49 52 56]': 52, '[68 71 75]': 53, '[55 58 61]': 54, '[51 54 58]': 55, '[51 55 58]': 56, '[59 62 65]': 57, '[63 66 70]': 58, '[62 65 68]': 59, '[50 53 57]': 60, '[47 51 54]': 61, '[55 59 62]': 62, '[56 60 63]': 63, '[56 59 62]': 64, '[44 48 51]': 65, '[46 50 53]': 66, '[56 59 63]': 67, '[65 69 72]': 68, '[57 60 63]': 69, '[63 66 69]': 70, '[58 61 64]': 71, '[52 56 59]': 72, '[52 55 58]': 73, '[69 72 75]': 74, '[60 64 67]': 75, '[67 71 74]': 76}\n","Decoder\n","{0: '[53 56 60]', 1: '[46 49 53]', 2: '[45 48 52]', 3: '[47 50 53]', 4: '[54 57 61]', 5: '[58 62 65]', 6: '[61 64 67]', 7: '[70 73 76]', 8: '[68 71 74]', 9: '[65 68 71]', 10: '[57 61 64]', 11: '[59 63 66]', 12: '[61 65 68]', 13: '[50 54 57]', 14: '[45 49 52]', 15: '[53 57 60]', 16: '[47 50 54]', 17: '[55 58 62]', 18: '[61 64 68]', 19: '[51 54 57]', 20: '[60 63 67]', 21: '[59 62 66]', 22: '[48 52 55]', 23: '[64 67 70]', 24: '[66 70 73]', 25: '[54 58 61]', 26: '[49 52 55]', 27: '[67 70 74]', 28: '[43 46 50]', 29: '[57 60 64]', 30: '[54 57 60]', 31: '[65 68 72]', 32: '[48 51 55]', 33: '[62 66 69]', 34: '[63 67 70]', 35: '[66 69 73]', 36: '[60 63 66]', 37: '[50 53 56]', 38: '[41 44 48]', 39: '[64 67 71]', 40: '[64 68 71]', 41: '[68 72 75]', 42: '[62 65 69]', 43: '[58 61 65]', 44: '[44 47 51]', 45: '[52 55 59]', 46: '[48 51 54]', 47: '[42 45 49]', 48: '[67 70 73]', 49: '[66 69 72]', 50: '[53 56 59]', 51: '[49 53 56]', 52: '[49 52 56]', 53: '[68 71 75]', 54: '[55 58 61]', 55: '[51 54 58]', 56: '[51 55 58]', 57: '[59 62 65]', 58: '[63 66 70]', 59: '[62 65 68]', 60: '[50 53 57]', 61: '[47 51 54]', 62: '[55 59 62]', 63: '[56 60 63]', 64: '[56 59 62]', 65: '[44 48 51]', 66: '[46 50 53]', 67: '[56 59 63]', 68: '[65 69 72]', 69: '[57 60 63]', 70: '[63 66 69]', 71: '[58 61 64]', 72: '[52 56 59]', 73: '[52 55 58]', 74: '[69 72 75]', 75: '[60 64 67]', 76: '[67 71 74]'}\n","Number of Chord Options: 77\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cd0x3Wg9VZt3","executionInfo":{"status":"ok","timestamp":1618526096541,"user_tz":420,"elapsed":1775,"user":{"displayName":"James Elliott","photoUrl":"","userId":"01294451348328680747"}},"outputId":"53a324ba-c2d9-431d-94d4-643555ecd218"},"source":["#EXAMPLE: Shows that x list is numbers that pertain to each chord in context\n","for context, target in quadgrams:\n","  x = [word_to_ix[str(w.numpy())] for w in context]\n","\n","print(quadgrams[-1][1].numpy())\n","print(x)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[58 62 65]\n","[17, 15, 17]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bR3cJ1ixT8jh"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"o8-R0tEB2KRU"},"source":["#helping function --> Max Output\n","\n","def modelRecommend(modelOutput, output_random = False,random_len = 2):\n","  \"\"\"\n","  Used to convert model_output to midi note values\n","  \"\"\"\n","  ##Extract Data from OUTPUT##\n","  modelOut = modelOutput.cpu()\n","  modelOut = modelOut.detach().numpy()\n","  modelOut = list(modelOut)\n","  finalOut = modelOut\n","  #print(modelOut.shape)\n","  #finalOut = list(modelOut[0]) --> ONLY use with \"Ngrams_FINAL\"\n","  ############################\n","\n","  #Method Decision --> Max vs Random\n","  if output_random == False:\n","    recommendedChord = finalOut.index(max(finalOut))\n","  else:\n","    #create copy with values sorted\n","    out_sorted = copy.copy(finalOut)\n","    out_sorted.sort(reverse = True) #Order greatest to least\n","    out_sorted = out_sorted[:random_len]\n","    ###############################################################\n","    #grab indexes of greatest values based on desired input length\n","    top_choice_indexes = []\n","    for i in range(len(out_sorted)):\n","      top_choice_indexes.append(finalOut.index(out_sorted[i]))\n","    ###############################################################\n","    #random selector\n","    recommendedChord = randint(0,len(top_choice_indexes)-1)\n","  \n","  return recommendedChord\n","\n","def modelRecommend_max(modelOutput):\n","  recommended_max = modelRecommend(modelOutput)\n","  return recommended_max\n","\n","def modelRecommend_to_oneHot(vocab_size,recommendedChord,returnNumpy=True):\n","  \"\"\"\n","  Output: \n","   1. return numpy array (default)\n","   2. return torch tensor array (if returnNumpy == False)\n","  \"\"\"\n","  one_hot = np.zeros(vocab_size)\n","  one_hot[recommendedChord] = 1\n","\n","  if returnNumpy == True:\n","    return one_hot\n","  else:\n","    tensorArray = torch.from_numpy(one_hot)\n","    tensorArray = torch.tensor(tensorArray, dtype=torch.long)\n","    return tensorArray\n","\n","def testModelOut(modelOutput):\n","  modelOut = modelOutput.cpu()\n","  modelOut = modelOut.detach().numpy()\n","  modelOut = list(modelOut)\n","  finalOut = modelOut\n","\n","  out_sorted = copy.copy(finalOut)\n","  out_sorted.sort(reverse = True) #Order greatest to least\n","\n","  top_choice_indexes = []\n","  for i in range(len(out_sorted)):\n","    top_choice_indexes.append(finalOut.index(out_sorted[i]))\n","\n","  print(top_choice_indexes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NWmRIKNFT-1Z"},"source":["class NGramLanguageModeler(nn.Module):\n","\n","    def __init__(self, vocab_size, embedding_dim, context_size):\n","        super(NGramLanguageModeler, self).__init__()\n","        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n","        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n","        self.linear2 = nn.Linear(128, vocab_size)\n","\n","    def forward(self, inputs):\n","        embeds = self.embeddings(inputs).view((1, -1))\n","        out = F.relu(self.linear1(embeds))\n","        out = self.linear2(out)\n","        log_probs = F.log_softmax(out, dim=1)\n","        return log_probs\n","###################################################################################################################\n","class NGram_LSTM_Model(nn.Module):\n","  def __init__(self, vocab_size, embedding_dim, context_size):\n","    super(NGram_LSTM_Model, self).__init__()\n","    self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n","    self.LSTM = nn.LSTM(embedding_dim, context_size,batch_first=True,num_layers=2)\n","    self.linear1 = nn.Linear(context_size, vocab_size) #output is length of vocab size because we have 77 options\n","\n","    self.embedding_dim = embedding_dim\n","    self.context_size = context_size\n","\n","  def forward(self, inputs):\n","    embeds = self.embeddings(inputs).view(1, self.context_size,self.embedding_dim)\n","    #print(embeds.shape)\n","    lstm_out, (ht,ct) = self.LSTM(embeds.view(1, self.context_size,self.embedding_dim))\n","    #print(\"lstm_out: \",lstm_out)\n","    out = self.linear1(lstm_out)\n","    #print(out.shape)\n","    log_probs = F.log_softmax(out, dim=1)\n","    #print(\"log probs: \",log_probs.shape)\n","    return log_probs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6qlTNZwzbzoC"},"source":["#initalize GPU & model\n","gpu = torch.cuda.get_device_name(0)\n","\n","#intialize\n","losses = []\n","loss_function = nn.NLLLoss()\n","model = NGram_LSTM_Model(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE).cuda()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpGBKfy3ucVx","executionInfo":{"status":"ok","timestamp":1618527004066,"user_tz":420,"elapsed":227,"user":{"displayName":"James Elliott","photoUrl":"","userId":"01294451348328680747"}},"outputId":"cb7ce23a-77cc-4ec7-a6d5-691e109fd3e6"},"source":["test = quadgrams[0]\n","target = test[1]\n","input = test[0]\n","print(\"Input: \\n{}\\n\\nTarget:\\n{}\\n\".format(input,target))\n","\n","Input_embed = word_to_ix[str(input[-1].numpy())]\n","Target_embed = word_to_ix[str(target.numpy())]\n","print(\"Conversion Test:\\nInput Embed: {}\\nTarget Embed: {}\".format(Input_embed,Target_embed))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: \n","[[55 59 62]\n"," [60 64 67]\n"," [62 66 69]]\n","\n","Target:\n","[64 67 71]\n","\n","Conversion Test:\n","Input Embed: 33\n","Target Embed: 39\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UFvTSR_UiOu5"},"source":["## Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YTllVKKFUdbB","executionInfo":{"status":"ok","timestamp":1618531844913,"user_tz":420,"elapsed":94301,"user":{"displayName":"James Elliott","photoUrl":"","userId":"01294451348328680747"}},"outputId":"4f7a1eb3-78e9-44c9-c264-4125cd3aedaf"},"source":["#train\n","input_data = quadgrams[:]\n","for epoch in range(200):\n","    total_loss = 0\n","\n","    total_accuracy = 0\n","    count = 0\n","    correct = 0\n","\n","    flag = True #change to false for testing\n","    for context, target in input_data:\n","        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n","        # into integer indices and wrap them in tensors)\n","        context_idxs = torch.tensor([word_to_ix[str(w.numpy())] for w in context], dtype=torch.long).cuda()\n","\n","        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n","        # new instance, you need to zero out the gradients from the old\n","        # instance\n","        model.zero_grad()\n","\n","        # Step 3. Run the forward pass, getting log probabilities over next\n","        # words\n","        log_probs = model.forward(context_idxs)\n","        log_probs = log_probs[0,-1,:] #collect only last time stamp\n","\n","        #grab recommendation\n","        recommendedChord = modelRecommend(log_probs)\n","\n","        # Step 4. Compute your loss function. (Again, Torch wants the target\n","        # word wrapped in a tensor)\n","        loss = loss_function(log_probs.view(1,-1), torch.tensor([word_to_ix[str(target.numpy())]], dtype=torch.long).cuda())\n","        #loss of form (one_hot_model_output,target_index)\n","\n","        #debug code\n","        if epoch == 0 and flag == False:\n","          print(\"Length of Model Output: \", len(log_probs[0]))\n","          print(\"model output: {}\\nTarget Chord: {}\".format(log_probs,\n","                                            word_to_ix[str(target.numpy())]))\n","          flag = True\n","\n","\n","        #Step 4a. Calculate Accuracy using recommended chord vs expected\n","        count += 1\n","        if recommendedChord == word_to_ix[str(target.numpy())]:\n","          correct += 1\n","\n","        # Step 5. Do the backward pass and update the gradient\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Get the Python number from a 1-element Tensor by calling tensor.item()\n","        total_loss += loss.item()\n","\n","    total_accuracy = correct/count\n","    print(\"Epoch: {}  Loss: {}  Accuracy: {}\".format(epoch,total_loss,total_accuracy))\n","    losses.append(total_loss)\n","    if total_loss < 10:\n","      #stop training if loss reaches the desired number\n","      break\n","\n","#final results of training session\n","print(\"Loss: \",losses)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 0  Loss: 1458.268099784851  Accuracy: 0.01977401129943503\n","Epoch: 1  Loss: 1066.5162625908852  Accuracy: 0.02754237288135593\n","Epoch: 2  Loss: 702.3290989845991  Accuracy: 0.03742937853107345\n","Epoch: 3  Loss: 388.8028229214251  Accuracy: 0.03531073446327684\n","Epoch: 4  Loss: 243.07171034999192  Accuracy: 0.04025423728813559\n","Epoch: 5  Loss: 160.77761341724545  Accuracy: 0.03884180790960452\n","Epoch: 6  Loss: 109.32313093589619  Accuracy: 0.03248587570621469\n","Epoch: 7  Loss: 77.80406990158372  Accuracy: 0.03531073446327684\n","Epoch: 8  Loss: 57.38034307747148  Accuracy: 0.03389830508474576\n","Epoch: 9  Loss: 43.511497175786644  Accuracy: 0.03177966101694915\n","Epoch: 10  Loss: 33.641937838168815  Accuracy: 0.03036723163841808\n","Epoch: 11  Loss: 25.831592370726867  Accuracy: 0.0346045197740113\n","Epoch: 12  Loss: 19.552832183799183  Accuracy: 0.046610169491525424\n","Epoch: 13  Loss: 15.406991601608752  Accuracy: 0.03954802259887006\n","Epoch: 14  Loss: 12.570545945080084  Accuracy: 0.03742937853107345\n","Epoch: 15  Loss: 10.483279733385643  Accuracy: 0.03531073446327684\n","Epoch: 16  Loss: 8.846272119547393  Accuracy: 0.03389830508474576\n","Loss:  [1458.268099784851, 1066.5162625908852, 702.3290989845991, 388.8028229214251, 243.07171034999192, 160.77761341724545, 109.32313093589619, 77.80406990158372, 57.38034307747148, 43.511497175786644, 33.641937838168815, 25.831592370726867, 19.552832183799183, 15.406991601608752, 12.570545945080084, 10.483279733385643, 8.846272119547393]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UCxjnctvwMg_"},"source":["## Save and Load Weights into Primary model"]},{"cell_type":"code","metadata":{"id":"ThLZSpMmbT7E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617825483688,"user_tz":420,"elapsed":269,"user":{"displayName":"James Elliott","photoUrl":"","userId":"01294451348328680747"}},"outputId":"cf0e66ae-abde-4cd2-f7df-4ebd014c0371"},"source":["#save model weights - MAKE SURE TO NOT OVERWRITE\n","model_weights_save_path = \"/content/drive/Shareddrives/Senior Design - Audio Project/MIDI Datasets/Models/NLP Models/state_dicts/embed_state_dict_model_example.pt\"\n","torch.save(model.state_dict(),model_weights_save_path)\n","print(\"weights saved\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["weights saved\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kvQTQZzBRuIy","executionInfo":{"status":"ok","timestamp":1618443852705,"user_tz":420,"elapsed":536,"user":{"displayName":"James Elliott","photoUrl":"","userId":"01294451348328680747"}},"outputId":"e261f5ae-8c38-4976-ec4c-d99d57fc96bf"},"source":["#LOAD MODEL WEIGHTS\n","load_path = \"/content/drive/Shareddrives/Senior Design - Audio Project/MIDI Datasets/Models/NLP Models/state_dicts/embed_state_dict_model_1inputs_100_dims.pt\"\n","model.load_state_dict(torch.load(load_path))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"d0mJC6NoCiQB"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qrBkBBRLCXA8","executionInfo":{"status":"ok","timestamp":1618529427468,"user_tz":420,"elapsed":4465,"user":{"displayName":"James Elliott","photoUrl":"","userId":"01294451348328680747"}},"outputId":"2acffb19-f36e-444b-e8f8-142f1039143c"},"source":["#evaluation of model\n","total_loss = 0\n","\n","total_accuracy = 0\n","counter = 0\n","correct = 0\n","\n","flag = True #change to false for testing\n","model.eval()\n","with torch.no_grad():\n","  for context, target in quadgrams:\n","      # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n","      # into integer indices and wrap them in tensors)\n","      context_idxs = torch.tensor([word_to_ix[str(w.numpy())] for w in context], dtype=torch.long).cuda()\n","\n","      # Step 3. Run the forward pass, getting log probabilities over next\n","      # words\n","      log_probs = model.forward(context_idxs)\n","      log_probs = log_probs[0,-1,:] #collect only last time stamp\n","\n","      # Step 4. Compute your loss function. (Again, Torch wants the target\n","      # word wrapped in a tensor)\n","      loss = loss_function(log_probs.view(1,-1), torch.tensor([word_to_ix[str(target.numpy())]], dtype=torch.long).cuda())\n","\n","\n","      #Step 4a. Calculate Accuracy\n","      recommendedChord = modelRecommend(log_probs)\n","      counter += 1\n","      expected = word_to_ix[str(target.numpy())]\n","      if recommendedChord == expected:\n","        correct += 1\n","        #print(\"Count: {}\\nCORRECT\\nrecommendedChord: {}\\nExpected: {}\\n\".format(counter,recommendedChord,expected))\n","      else:\n","        pass\n","        print(expected,recommendedChord)\n","        #print(\"Count: {}\\nFAIL\\nrecommendedChord: {}\\nExpected: {}\\n\".format(counter,recommendedChord,expected))\n","\n","      # Get the Python number from a 1-element Tensor by calling tensor.item()\n","      total_loss += loss.item()\n","\n","  total_accuracy = correct/counter\n","  print(\"Loss: {}  Accuracy: {}\".format(total_loss,total_accuracy))\n","\n","#Inference Test\n","print(\"\\n\\nInference Speed Test...\")\n","t_start = time.time()\n","test_data = quadgrams[0]\n","input = test_data[0]\n","target = test_data[1]\n","\n","model.eval()\n","with torch.no_grad():\n","  context_idxs = torch.tensor([word_to_ix[str(w.numpy())] for w in input], dtype=torch.long).cuda()\n","\n","  log_probs = model(context_idxs)\n","  log_probs = log_probs[0,0,:] #collect only last time stamp\n","  ##########################################\n","  #prints index order based on greatest to least values\n","  testModelOut(log_probs)\n","  \n","  ###########################################\n","  recommendedChord = modelRecommend(log_probs)\n","  final_chord = decoder(recommendedChord)\n","  print(\"Target Chord: {}, dict_number: {}\".format(target,word_to_ix[str(target.numpy())]))\n","  print(\"final chord: {} dict_number: {}\\n\".format(final_chord,recommendedChord))\n","  print(\"Eval Time: {}(seconds)\".format(time.time() - t_start))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["39 34\n","39 29\n","75 29\n","29 11\n","33 29\n","39 11\n","21 63\n","62 49\n","39 12\n","33 49\n","75 34\n","33 34\n","75 11\n","21 11\n","29 11\n","75 29\n","21 29\n","62 11\n","33 11\n","39 29\n","75 43\n","33 11\n","33 34\n","29 61\n","21 61\n","33 29\n","39 43\n","33 34\n","39 11\n","33 11\n","62 11\n","33 34\n","75 29\n","62 29\n","21 34\n","33 11\n","49 61\n","33 62\n","39 34\n","29 34\n","75 11\n","33 29\n","33 29\n","62 29\n","75 11\n","33 11\n","39 29\n","29 62\n","39 29\n","75 29\n","33 29\n","33 61\n","62 43\n","62 11\n","21 11\n","33 29\n","63 11\n","31 11\n","12 11\n","34 11\n","63 11\n","63 11\n","34 11\n","34 11\n","34 11\n","63 11\n","43 11\n","34 11\n","43 11\n","48 11\n","20 11\n","34 11\n","34 11\n","34 11\n","12 11\n","43 11\n","63 11\n","20 11\n","31 11\n","12 11\n","63 11\n","63 11\n","34 11\n","43 11\n","63 11\n","34 11\n","31 11\n","12 11\n","31 11\n","31 11\n","43 11\n","31 11\n","34 11\n","12 11\n","34 11\n","63 11\n","63 11\n","43 11\n","43 11\n","43 11\n","20 43\n","31 11\n","12 11\n","34 11\n","12 11\n","31 11\n","34 11\n","12 11\n","20 11\n","34 11\n","63 11\n","34 11\n","43 11\n","31 11\n","34 11\n","34 11\n","20 11\n","31 11\n","12 11\n","20 11\n","18 11\n","40 11\n","24 11\n","58 11\n","24 11\n","53 11\n","18 11\n","24 11\n","53 11\n","40 20\n","53 11\n","53 11\n","53 20\n","40 20\n","40 11\n","24 63\n","53 20\n","58 11\n","24 11\n","24 11\n","18 11\n","24 20\n","58 11\n","40 11\n","40 34\n","58 11\n","18 20\n","24 11\n","18 20\n","53 11\n","24 34\n","7 34\n","24 34\n","18 11\n","24 11\n","18 11\n","58 11\n","24 11\n","58 11\n","24 11\n","24 11\n","40 11\n","53 11\n","18 34\n","24 11\n","53 11\n","11 34\n","24 34\n","24 11\n","40 34\n","40 11\n","53 34\n","18 11\n","24 11\n","18 11\n","11 12\n","10 12\n","4 11\n","10 11\n","72 11\n","72 34\n","72 11\n","72 34\n","72 11\n","72 11\n","18 11\n","67 12\n","4 11\n","11 12\n","4 11\n","11 12\n","10 12\n","4 11\n","72 11\n","18 11\n","70 12\n","67 11\n","10 11\n","4 11\n","10 11\n","72 11\n","4 11\n","67 11\n","18 11\n","18 11\n","4 11\n","10 11\n","67 11\n","10 11\n","67 11\n","18 11\n","18 11\n","4 11\n","72 34\n","18 11\n","18 11\n","18 11\n","72 11\n","72 11\n","10 11\n","67 11\n","10 11\n","4 11\n","21 62\n","10 11\n","13 11\n","21 29\n","4 11\n","10 29\n","10 11\n","45 11\n","62 11\n","4 11\n","10 62\n","21 11\n","62 11\n","4 29\n","10 11\n","10 73\n","62 11\n","10 11\n","21 11\n","13 29\n","45 11\n","45 11\n","62 29\n","10 63\n","21 11\n","13 62\n","62 11\n","45 11\n","21 11\n","13 11\n","10 11\n","4 29\n","13 11\n","4 11\n","13 11\n","10 11\n","13 29\n","21 11\n","21 11\n","45 11\n","45 11\n","10 11\n","10 63\n","10 11\n","21 11\n","45 11\n","10 11\n","45 73\n","62 11\n","10 63\n","62 11\n","10 11\n","6 63\n","13 62\n","21 11\n","13 29\n","45 11\n","4 11\n","13 29\n","62 11\n","10 11\n","13 73\n","10 73\n","29 61\n","17 11\n","75 11\n","15 11\n","75 11\n","23 11\n","5 11\n","75 34\n","17 61\n","15 11\n","75 61\n","15 34\n","15 11\n","75 11\n","42 61\n","75 11\n","17 11\n","15 11\n","42 34\n","15 11\n","15 11\n","75 11\n","42 11\n","5 11\n","75 11\n","5 29\n","75 29\n","17 11\n","17 29\n","5 11\n","42 11\n","42 34\n","75 34\n","75 11\n","15 34\n","15 11\n","5 11\n","29 34\n","15 11\n","42 34\n","75 11\n","5 11\n","75 11\n","75 29\n","5 11\n","42 11\n","42 11\n","17 29\n","42 29\n","15 34\n","75 34\n","17 29\n","75 34\n","17 11\n","29 11\n","75 11\n","5 11\n","75 11\n","17 11\n","5 34\n","42 11\n","29 34\n","55 11\n","51 11\n","43 63\n","51 11\n","63 11\n","63 11\n","51 11\n","0 12\n","55 11\n","36 12\n","63 11\n","25 12\n","63 12\n","43 11\n","51 34\n","25 11\n","63 11\n","0 11\n","63 12\n","55 34\n","51 0\n","25 11\n","63 11\n","55 11\n","63 12\n","63 34\n","25 12\n","51 34\n","51 11\n","43 11\n","43 11\n","63 11\n","43 11\n","25 11\n","63 11\n","0 11\n","63 11\n","51 11\n","63 11\n","55 11\n","43 11\n","0 11\n","63 11\n","63 11\n","55 11\n","51 11\n","43 34\n","55 11\n","63 11\n","25 11\n","25 11\n","55 11\n","0 11\n","0 11\n","25 20\n","43 11\n","43 63\n","55 11\n","63 11\n","51 11\n","51 34\n","63 11\n","43 11\n","25 63\n","62 29\n","22 29\n","29 12\n","62 12\n","62 12\n","15 12\n","62 10\n","22 11\n","22 62\n","60 29\n","22 29\n","45 12\n","60 34\n","62 12\n","57 29\n","60 12\n","62 29\n","62 34\n","60 29\n","62 29\n","29 12\n","15 12\n","45 12\n","22 29\n","22 12\n","62 34\n","15 29\n","22 62\n","29 11\n","22 29\n","60 11\n","62 11\n","29 73\n","60 73\n","22 62\n","15 29\n","45 73\n","22 73\n","15 29\n","15 29\n","45 73\n","62 29\n","60 29\n","15 11\n","45 29\n","62 11\n","62 73\n","45 12\n","60 12\n","60 29\n","62 11\n","15 73\n","62 11\n","62 29\n","62 34\n","29 73\n","22 29\n","29 73\n","15 29\n","5 34\n","27 34\n","5 11\n","68 34\n","20 34\n","68 11\n","42 34\n","27 34\n","27 34\n","20 34\n","20 34\n","34 11\n","27 11\n","68 34\n","34 29\n","5 34\n","42 34\n","68 34\n","68 34\n","68 34\n","20 34\n","27 34\n","68 34\n","42 29\n","42 34\n","20 34\n","27 34\n","5 29\n","68 34\n","27 34\n","5 34\n","68 11\n","68 34\n","74 34\n","68 34\n","27 11\n","68 34\n","68 34\n","5 34\n","5 34\n","42 11\n","68 34\n","68 34\n","5 34\n","20 11\n","68 34\n","27 34\n","20 34\n","20 34\n","20 34\n","5 34\n","68 34\n","68 34\n","5 34\n","42 34\n","27 11\n","5 34\n","35 43\n","33 11\n","33 11\n","10 34\n","40 34\n","33 34\n","18 34\n","40 11\n","40 12\n","21 34\n","21 34\n","40 34\n","40 11\n","33 34\n","35 34\n","40 34\n","40 11\n","10 11\n","18 11\n","35 34\n","18 11\n","35 11\n","21 11\n","35 11\n","10 11\n","40 11\n","35 34\n","40 11\n","10 11\n","18 11\n","21 11\n","33 34\n","21 11\n","35 11\n","40 11\n","33 11\n","35 34\n","35 11\n","40 34\n","40 11\n","33 34\n","40 11\n","33 11\n","21 34\n","10 34\n","10 11\n","21 11\n","35 11\n","18 11\n","18 11\n","40 11\n","40 11\n","10 11\n","10 11\n","8 34\n","40 11\n","33 11\n","10 11\n","10 12\n","21 11\n","40 11\n","10 11\n","21 11\n","40 34\n","17 11\n","56 43\n","56 34\n","0 11\n","20 11\n","5 11\n","20 11\n","63 11\n","0 11\n","5 11\n","5 11\n","56 11\n","63 11\n","5 11\n","56 11\n","17 11\n","20 11\n","5 34\n","5 11\n","5 11\n","0 11\n","5 11\n","59 11\n","0 11\n","56 11\n","5 11\n","63 34\n","63 11\n","5 11\n","56 11\n","56 11\n","5 11\n","20 11\n","5 11\n","20 11\n","56 43\n","20 11\n","0 11\n","63 11\n","56 11\n","17 11\n","0 11\n","17 11\n","5 11\n","0 11\n","5 11\n","5 11\n","0 11\n","20 11\n","17 11\n","63 11\n","5 11\n","63 11\n","63 11\n","5 11\n","56 11\n","0 11\n","20 34\n","63 11\n","17 11\n","20 11\n","56 11\n","20 11\n","5 11\n","12 11\n","12 11\n","43 11\n","58 11\n","67 11\n","25 11\n","67 11\n","25 11\n","58 12\n","12 11\n","25 11\n","25 11\n","67 11\n","12 63\n","12 11\n","12 11\n","58 63\n","12 11\n","25 12\n","25 11\n","12 11\n","67 63\n","25 11\n","12 11\n","67 11\n","43 63\n","9 11\n","12 11\n","12 11\n","25 11\n","43 11\n","58 11\n","67 11\n","58 11\n","12 11\n","43 11\n","43 11\n","58 11\n","58 11\n","67 11\n","12 11\n","25 11\n","12 11\n","11 12\n","25 11\n","12 11\n","58 11\n","58 12\n","58 11\n","67 12\n","25 11\n","43 11\n","67 11\n","17 11\n","56 11\n","66 11\n","63 11\n","17 34\n","17 11\n","0 34\n","37 34\n","17 11\n","37 11\n","32 11\n","17 11\n","56 34\n","56 12\n","65 11\n","56 11\n","56 11\n","66 12\n","5 11\n","5 11\n","32 12\n","56 43\n","56 43\n","63 11\n","0 43\n","0 11\n","56 11\n","17 11\n","0 34\n","56 12\n","0 11\n","5 43\n","17 43\n","65 29\n","63 12\n","0 11\n","17 11\n","66 11\n","63 11\n","66 11\n","37 11\n","28 63\n","32 11\n","28 34\n","0 11\n","65 34\n","66 11\n","56 11\n","66 11\n","37 11\n","0 11\n","56 11\n","0 34\n","63 11\n","21 11\n","72 29\n","72 11\n","52 11\n","72 11\n","64 11\n","72 11\n","18 11\n","13 11\n","10 11\n","4 11\n","18 11\n","64 11\n","52 11\n","21 11\n","10 11\n","21 11\n","10 11\n","13 11\n","18 43\n","33 11\n","21 11\n","21 11\n","10 11\n","10 11\n","33 43\n","18 11\n","10 11\n","10 11\n","18 11\n","64 43\n","72 11\n","40 11\n","64 11\n","72 11\n","10 11\n","18 11\n","4 43\n","33 11\n","4 11\n","21 11\n","10 12\n","10 11\n","18 11\n","13 11\n","21 11\n","10 11\n","40 11\n","21 11\n","33 11\n","21 11\n","40 11\n","33 11\n","18 11\n","15 11\n","17 11\n","22 29\n","15 11\n","22 11\n","5 11\n","73 12\n","15 29\n","29 11\n","29 11\n","75 11\n","73 11\n","15 34\n","15 12\n","66 11\n","5 29\n","29 34\n","60 11\n","15 11\n","60 11\n","15 11\n","17 11\n","15 11\n","29 11\n","17 34\n","66 12\n","5 11\n","75 43\n","17 11\n","17 11\n","5 11\n","15 43\n","75 34\n","17 11\n","29 34\n","2 62\n","17 29\n","60 29\n","22 43\n","22 29\n","66 11\n","73 43\n","15 11\n","22 29\n","29 11\n","22 29\n","73 11\n","17 11\n","2 11\n","17 11\n","5 29\n","15 11\n","67 43\n","61 34\n","4 43\n","61 20\n","61 34\n","4 11\n","19 34\n","19 63\n","14 11\n","10 43\n","72 58\n","14 11\n","44 0\n","52 43\n","4 34\n","4 11\n","44 11\n","11 34\n","19 34\n","61 34\n","72 11\n","61 29\n","19 11\n","67 11\n","72 11\n","72 34\n","72 34\n","61 34\n","67 11\n","14 11\n","67 34\n","10 11\n","67 11\n","52 11\n","4 11\n","67 63\n","72 11\n","72 11\n","10 11\n","10 11\n","10 34\n","72 34\n","4 11\n","72 11\n","52 11\n","4 34\n","72 11\n","67 11\n","67 11\n","4 11\n","4 34\n","72 11\n","12 11\n","31 11\n","31 11\n","12 11\n","31 11\n","63 11\n","43 11\n","36 12\n","12 11\n","41 11\n","25 11\n","36 11\n","24 11\n","31 11\n","24 11\n","24 11\n","12 11\n","31 11\n","12 11\n","31 11\n","24 0\n","63 11\n","58 11\n","41 11\n","12 11\n","43 0\n","31 11\n","12 0\n","31 11\n","12 11\n","58 11\n","58 11\n","63 11\n","58 11\n","58 11\n","63 11\n","41 11\n","36 11\n","58 11\n","0 11\n","25 12\n","36 11\n","24 11\n","12 11\n","58 11\n","58 11\n","58 11\n","25 11\n","63 11\n","63 11\n","0 11\n","43 11\n","12 11\n","15 11\n","42 11\n","57 29\n","75 11\n","75 29\n","68 11\n","62 29\n","29 11\n","45 11\n","45 11\n","39 11\n","42 29\n","62 43\n","57 29\n","42 11\n","75 34\n","42 11\n","39 34\n","75 34\n","42 34\n","68 29\n","15 43\n","29 11\n","62 73\n","42 29\n","68 11\n","76 34\n","76 34\n","57 29\n","75 11\n","39 29\n","75 11\n","57 11\n","76 34\n","39 34\n","62 11\n","75 34\n","42 34\n","42 11\n","68 29\n","75 11\n","39 29\n","75 34\n","39 34\n","68 11\n","39 34\n","39 29\n","15 29\n","42 34\n","75 29\n","62 29\n","75 11\n","67 43\n","61 34\n","19 34\n","4 11\n","61 20\n","19 63\n","61 34\n","14 11\n","4 43\n","52 43\n","14 11\n","4 11\n","44 0\n","10 43\n","72 58\n","4 34\n","44 11\n","72 34\n","72 11\n","19 11\n","72 34\n","61 29\n","67 11\n","61 34\n","11 34\n","72 11\n","19 34\n","4 11\n","14 11\n","10 11\n","72 11\n","67 11\n","67 34\n","67 11\n","61 34\n","67 63\n","52 11\n","72 11\n","4 11\n","67 11\n","4 34\n","72 34\n","10 11\n","10 11\n","52 11\n","72 11\n","72 11\n","67 11\n","10 34\n","4 11\n","4 34\n","72 11\n","40 11\n","40 11\n","24 11\n","18 11\n","24 11\n","18 11\n","18 11\n","40 11\n","58 11\n","67 11\n","58 11\n","18 11\n","58 11\n","71 11\n","72 11\n","40 11\n","67 11\n","58 11\n","58 11\n","71 11\n","25 11\n","24 11\n","18 11\n","72 11\n","58 11\n","25 11\n","55 11\n","58 11\n","40 11\n","18 11\n","18 11\n","55 11\n","18 11\n","25 11\n","71 11\n","25 11\n","67 11\n","25 11\n","72 11\n","71 11\n","58 11\n","25 11\n","18 63\n","51 11\n","43 11\n","43 11\n","25 63\n","43 11\n","67 11\n","25 11\n","11 63\n","25 63\n","55 11\n","43 63\n","25 11\n","61 11\n","25 63\n","43 11\n","25 12\n","12 11\n","25 43\n","55 11\n","12 11\n","67 63\n","50 63\n","50 11\n","25 11\n","43 11\n","67 11\n","51 63\n","12 43\n","43 11\n","67 43\n","67 11\n","25 11\n","50 11\n","51 11\n","51 11\n","51 11\n","67 11\n","61 34\n","25 12\n","61 20\n","67 12\n","1 20\n","55 11\n","67 11\n","1 27\n","67 20\n","50 11\n","51 11\n","25 11\n","62 11\n","33 29\n","30 34\n","62 73\n","21 11\n","45 34\n","62 11\n","13 29\n","22 11\n","21 29\n","62 29\n","30 73\n","75 11\n","62 29\n","29 11\n","21 11\n","62 29\n","13 11\n","75 34\n","21 29\n","21 11\n","21 34\n","21 11\n","62 29\n","45 29\n","33 11\n","33 29\n","62 11\n","75 29\n","29 11\n","29 11\n","75 29\n","30 29\n","22 29\n","30 29\n","21 29\n","13 29\n","13 62\n","29 11\n","13 29\n","62 29\n","29 11\n","29 62\n","62 29\n","45 11\n","22 62\n","16 62\n","16 29\n","13 29\n","75 11\n","32 11\n","43 11\n","54 11\n","43 11\n","51 11\n","0 11\n","43 11\n","54 11\n","12 11\n","56 11\n","56 34\n","20 11\n","43 11\n","63 11\n","63 11\n","56 11\n","32 11\n","63 11\n","34 11\n","12 11\n","56 11\n","0 11\n","43 11\n","51 11\n","12 11\n","43 11\n","43 11\n","63 11\n","20 11\n","54 11\n","54 12\n","20 11\n","63 12\n","43 11\n","34 11\n","20 11\n","63 11\n","34 11\n","63 11\n","56 34\n","63 11\n","20 11\n","63 34\n","51 11\n","63 11\n","43 11\n","20 11\n","63 11\n","20 11\n","0 11\n","20 11\n","56 34\n","12 11\n","12 11\n","20 34\n","17 34\n","69 34\n","56 11\n","20 11\n","60 11\n","5 11\n","15 11\n","15 43\n","56 11\n","5 34\n","42 34\n","60 11\n","20 11\n","15 11\n","5 11\n","17 29\n","69 34\n","20 11\n","15 34\n","20 34\n","34 29\n","5 11\n","68 34\n","20 34\n","5 29\n","20 34\n","42 34\n","42 34\n","68 11\n","20 34\n","42 34\n","5 11\n","15 11\n","5 11\n","5 11\n","68 34\n","5 11\n","15 11\n","69 34\n","20 34\n","42 11\n","17 34\n","56 11\n","5 11\n","69 11\n","42 34\n","42 34\n","42 11\n","5 11\n","Loss: 13.450852444403644  Accuracy: 0.06497175141242938\n","\n","\n","Inference Speed Test...\n","[66, 28, 47, 3, 46, 38, 26, 70, 49, 9, 59, 48, 23, 6, 41, 7, 36, 74, 65, 64, 8, 37, 2, 71, 50, 32, 54, 14, 1, 44, 16, 35, 69, 12, 30, 76, 52, 57, 55, 53, 31, 58, 73, 61, 72, 0, 63, 51, 56, 24, 19, 22, 27, 13, 25, 45, 40, 60, 18, 43, 39, 42, 67, 68, 10, 17, 15, 20, 5, 4, 62, 75, 21, 11, 33, 34, 29]\n","Target Chord: [64 67 71], dict_number: 39\n","final chord: [46, 50, 53] dict_number: 66\n","\n","Eval Time: 0.003858327865600586(seconds)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AtN_idZqL5pW"},"source":["# Results\n","                Eval Accuracy\n","1. 3 chord inputs: \n","2. 2 Chord inputs:  \n","3. 1 Chord inputs:  "]},{"cell_type":"code","metadata":{"id":"_jKUuk_f8LCI"},"source":["def combineInputOutput(input_notes_decoded_ndArray,recommendedChord_encoded):\n","  \"\"\"\n","  takes input to model (decoded) form & take recommendedChord (encoded),\n","  and outputs the two into list form for listToMidi()\n","  \"\"\"\n","  #convert input array to list of lists\n","  input_chord = input_notes_decoded_ndArray.numpy()\n","  input_chord = input_chord.toList\n","\n","  #decode output\n","  next_chord = decoder(code=recommendedChord_encoded)\n","\n","  #update original with next_chord\n","  input_chord.append(next_chord)\n","\n","  return input_chord\n","###########################################################################################\n","###############################SINGLE MODEL RUN FROM NLP_FINAL#############################\n","def modelRunSingle(dataIn,model,saveMidi=True,output_random=False,save_path=True,count=0):\n","  #inference for chunk of dataset\n","  model.eval()\n","  with torch.no_grad():\n","    #seperate tuple of input data\n","    context = dataIn\n","\n","    midi_out = []\n","    #time grabber for inference calculations\n","    dt = time.time()\n","    #convert input to model form\n","    context_idxs = torch.tensor([word_to_ix[str(w.numpy())] for w in context], dtype=torch.long).cuda()\n","    #print(context)\n","\n","    #run model\n","    log_probs, = model(context_idxs)\n","    #print(\"model output: {}\\n\".format(log_probs))\n","\n","    #Chord Selection\n","    recommendedChord = modelRecommend(log_probs,output_random=output_random)#########################################################################################\n","    #print(\"encoded recomendation {}\\n\".format(recommendedChord))\n","\n","    #Decode cord\n","    recommendation = decoder(code=recommendedChord)\n","    #print(\"recommendation: {}\\n\".format(recommendation))\n","\n","    #append decode to input for musicCompletor\n","    midi_input = np.append(context,[recommendation],axis=0)\n","    #print(midi_input)\n","\n","    #save to midi file\n","    if save_path == True:\n","      file_name = BASE_FILE_NAME + str(count) + HANDLE\n","      file_path = os.path.join(SAVE_DIR,file_name)\n","    else:\n","      file_name = BASE_FILE_NAME + str(count) + HANDLE\n","      file_path = os.path.join(r\"./\",file_name)\n","    #print(\"path\\n{}\".format(file_path))\n","    count += 1\n","    if saveMidi == True:\n","      listToMidi(midi_input,completePath=file_path,printOut=False)\n","      print(\"file saved at:\\n{}\".format(file_path))\n","\n","    midi_out.append(midi_input)\n","    return midi_out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x52Lv3B89wT7","executionInfo":{"status":"ok","timestamp":1618524131986,"user_tz":420,"elapsed":268,"user":{"displayName":"James Elliott","photoUrl":"","userId":"01294451348328680747"}},"outputId":"a75c2f2b-9348-44b8-eada-5fbbf4479ce2"},"source":["#variables\n","SAVE_DIR = r\"/content/drive/Shareddrives/Senior Design - Audio Project/MIDI Datasets/Models/NLP Models/midiOutputs\"\n","BASE_FILE_NAME = r\"song_\"\n","HANDLE = r\".mid\"\n","#input data for testing\n","test_data = quadgrams[0:4]\n","\n","i = 0\n","for context, target in test_data:\n","  output_midi_list = modelRunSingle(context,model,saveMidi=True,output_random=True,save_path=False,count=i)\n","  i += 1\n","  print(output_midi_list)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["file saved at:\n","./song_0.mid\n","[array([[55, 59, 62],\n","       [60, 64, 67],\n","       [62, 66, 69],\n","       [53, 56, 60]])]\n","file saved at:\n","./song_1.mid\n","[array([[55, 59, 62],\n","       [54, 57, 60],\n","       [64, 67, 71],\n","       [53, 56, 60]])]\n","file saved at:\n","./song_2.mid\n","[array([[55, 59, 62],\n","       [54, 57, 60],\n","       [64, 67, 71],\n","       [53, 56, 60]])]\n","file saved at:\n","./song_3.mid\n","[array([[55, 59, 62],\n","       [54, 57, 60],\n","       [59, 62, 66],\n","       [53, 56, 60]])]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W7TeAeNSe8cf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FU5IO13O6LkX","executionInfo":{"status":"ok","timestamp":1618513572632,"user_tz":420,"elapsed":659,"user":{"displayName":"James Elliott","photoUrl":"","userId":"01294451348328680747"}},"outputId":"1bee0621-50f0-4bd5-a8ca-124a44829270"},"source":["input_chord = input.numpy()\n","input_chord = input_chord.tolist()\n","input_chord"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[55, 59, 62], [60, 64, 67], [62, 66, 69]]"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"id":"M5PcWySkMIei","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618513573352,"user_tz":420,"elapsed":354,"user":{"displayName":"James Elliott","photoUrl":"","userId":"01294451348328680747"}},"outputId":"b4189f72-22e5-4e31-b5cd-b3ce87fbddc4"},"source":["next_chord = decoder(code=recommendedChord)\n","next_chord"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[60, 63, 67]"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aZuKm68P6SvH","executionInfo":{"status":"ok","timestamp":1618513633389,"user_tz":420,"elapsed":627,"user":{"displayName":"James Elliott","photoUrl":"","userId":"01294451348328680747"}},"outputId":"eb679f04-af60-4dec-c08c-9363ffe27865"},"source":["print(input_chord)\n","print(next_chord)\n","\n","input_chord.append(next_chord)\n","listToMidi(input_chord,printOut=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[55, 59, 62], [60, 64, 67], [62, 66, 69], [60, 63, 67]]\n","[60, 63, 67]\n","program_change channel=0 program=12 time=0\n","note_on channel=0 note=55 velocity=64 time=0.26666666666666666\n","note_on channel=0 note=59 velocity=64 time=0\n","note_on channel=0 note=62 velocity=64 time=0\n","note_off channel=0 note=55 velocity=127 time=0.26666666666666666\n","note_off channel=0 note=59 velocity=127 time=0\n","note_off channel=0 note=62 velocity=127 time=0\n","note_on channel=0 note=60 velocity=64 time=0.26666666666666666\n","note_on channel=0 note=64 velocity=64 time=0\n","note_on channel=0 note=67 velocity=64 time=0\n","note_off channel=0 note=60 velocity=127 time=0.26666666666666666\n","note_off channel=0 note=64 velocity=127 time=0\n","note_off channel=0 note=67 velocity=127 time=0\n","note_on channel=0 note=62 velocity=64 time=0.26666666666666666\n","note_on channel=0 note=66 velocity=64 time=0\n","note_on channel=0 note=69 velocity=64 time=0\n","note_off channel=0 note=62 velocity=127 time=0.26666666666666666\n","note_off channel=0 note=66 velocity=127 time=0\n","note_off channel=0 note=69 velocity=127 time=0\n","note_on channel=0 note=60 velocity=64 time=0.26666666666666666\n","note_on channel=0 note=63 velocity=64 time=0\n","note_on channel=0 note=67 velocity=64 time=0\n","note_off channel=0 note=60 velocity=127 time=0.26666666666666666\n","note_off channel=0 note=63 velocity=127 time=0\n","note_off channel=0 note=67 velocity=127 time=0\n","note_on channel=0 note=60 velocity=64 time=0.26666666666666666\n","note_on channel=0 note=63 velocity=64 time=0\n","note_on channel=0 note=67 velocity=64 time=0\n","note_off channel=0 note=60 velocity=127 time=0.26666666666666666\n","note_off channel=0 note=63 velocity=127 time=0\n","note_off channel=0 note=67 velocity=127 time=0\n","<meta message end_of_track time=0>\n","\n","file saved @\n","./new_song.mid\n"],"name":"stdout"}]}]}